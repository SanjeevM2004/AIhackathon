{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e4d7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458ce5d1",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9db86cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PS3train = pd.read_csv(\"PS3_train.csv\")\n",
    "PS3test = pd.read_csv(\"PS3_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6193576f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>uid</th>\n",
       "      <th>target_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Premium quality five pocket jean from Wrangler...</td>\n",
       "      <td>Amazon.com: Wrangler Men's Rugged Wear Relaxed...</td>\n",
       "      <td>B0000CBALT</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you're looking for a different kind of anim...</td>\n",
       "      <td>Sakura Diaries - Complete Series Collector's E...</td>\n",
       "      <td>B00005QFDT</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First things first: Yes, Thinking XXX features...</td>\n",
       "      <td>Thinking XXX (Extended Cut) (2006)</td>\n",
       "      <td>B000BNXD50</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feathertouch. 100% Polyester Machine Wash Warm...</td>\n",
       "      <td>Amazon.com: Petite Feathertouch Pull-On Pant: ...</td>\n",
       "      <td>B0002LK9V2</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When you need outstanding fuel delivery, easy ...</td>\n",
       "      <td>ACDelco EP386 Fuel Pump</td>\n",
       "      <td>B000C9PA54</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35107</th>\n",
       "      <td>SArah Walker, Anthony Rolfe Johnson, Jean Rigb...</td>\n",
       "      <td>Britten - Gloriana (1984)</td>\n",
       "      <td>B000I2IUM0</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35108</th>\n",
       "      <td>Buy Teenage Mutant Ninja Turtles 4: Turtles in...</td>\n",
       "      <td>Teenage Mutant Ninja Turtles IV: Turtles in Time</td>\n",
       "      <td>B000035Y3N</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35109</th>\n",
       "      <td>A 10 movie collection of women action flicks. ...</td>\n",
       "      <td>Women Who Kick Butt 10 Movie Pack (2001)</td>\n",
       "      <td>B00005B7BW</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35110</th>\n",
       "      <td>This huarache sandal is designed for all-day c...</td>\n",
       "      <td>Softspots Women's Tela Leather Sandal</td>\n",
       "      <td>B0002KIFAK</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35111</th>\n",
       "      <td>The Wrangler Cowboy Cut jean is a Western Wear...</td>\n",
       "      <td>Amazon.com: Wrangler Men's Big &amp;amp; Tall Cowb...</td>\n",
       "      <td>B000FA2832</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35112 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  \\\n",
       "0      Premium quality five pocket jean from Wrangler...   \n",
       "1      If you're looking for a different kind of anim...   \n",
       "2      First things first: Yes, Thinking XXX features...   \n",
       "3      Feathertouch. 100% Polyester Machine Wash Warm...   \n",
       "4      When you need outstanding fuel delivery, easy ...   \n",
       "...                                                  ...   \n",
       "35107  SArah Walker, Anthony Rolfe Johnson, Jean Rigb...   \n",
       "35108  Buy Teenage Mutant Ninja Turtles 4: Turtles in...   \n",
       "35109  A 10 movie collection of women action flicks. ...   \n",
       "35110  This huarache sandal is designed for all-day c...   \n",
       "35111  The Wrangler Cowboy Cut jean is a Western Wear...   \n",
       "\n",
       "                                                   title         uid  \\\n",
       "0      Amazon.com: Wrangler Men's Rugged Wear Relaxed...  B0000CBALT   \n",
       "1      Sakura Diaries - Complete Series Collector's E...  B00005QFDT   \n",
       "2                     Thinking XXX (Extended Cut) (2006)  B000BNXD50   \n",
       "3      Amazon.com: Petite Feathertouch Pull-On Pant: ...  B0002LK9V2   \n",
       "4                                ACDelco EP386 Fuel Pump  B000C9PA54   \n",
       "...                                                  ...         ...   \n",
       "35107                          Britten - Gloriana (1984)  B000I2IUM0   \n",
       "35108   Teenage Mutant Ninja Turtles IV: Turtles in Time  B000035Y3N   \n",
       "35109           Women Who Kick Butt 10 Movie Pack (2001)  B00005B7BW   \n",
       "35110              Softspots Women's Tela Leather Sandal  B0002KIFAK   \n",
       "35111  Amazon.com: Wrangler Men's Big &amp; Tall Cowb...  B000FA2832   \n",
       "\n",
       "       target_ind  \n",
       "0             247  \n",
       "1             453  \n",
       "2             228  \n",
       "3             223  \n",
       "4             312  \n",
       "...           ...  \n",
       "35107         473  \n",
       "35108          74  \n",
       "35109         460  \n",
       "35110         158  \n",
       "35111         340  \n",
       "\n",
       "[35112 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PS3train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd79110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PS3train = PS3train.reindex(columns = [\"target_ind\", \"content\", \"title\", \"uid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8ebdad28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_ind</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>247</td>\n",
       "      <td>Premium quality five pocket jean from Wrangler...</td>\n",
       "      <td>Amazon.com: Wrangler Men's Rugged Wear Relaxed...</td>\n",
       "      <td>B0000CBALT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>453</td>\n",
       "      <td>If you're looking for a different kind of anim...</td>\n",
       "      <td>Sakura Diaries - Complete Series Collector's E...</td>\n",
       "      <td>B00005QFDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228</td>\n",
       "      <td>First things first: Yes, Thinking XXX features...</td>\n",
       "      <td>Thinking XXX (Extended Cut) (2006)</td>\n",
       "      <td>B000BNXD50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>223</td>\n",
       "      <td>Feathertouch. 100% Polyester Machine Wash Warm...</td>\n",
       "      <td>Amazon.com: Petite Feathertouch Pull-On Pant: ...</td>\n",
       "      <td>B0002LK9V2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312</td>\n",
       "      <td>When you need outstanding fuel delivery, easy ...</td>\n",
       "      <td>ACDelco EP386 Fuel Pump</td>\n",
       "      <td>B000C9PA54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35107</th>\n",
       "      <td>473</td>\n",
       "      <td>SArah Walker, Anthony Rolfe Johnson, Jean Rigb...</td>\n",
       "      <td>Britten - Gloriana (1984)</td>\n",
       "      <td>B000I2IUM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35108</th>\n",
       "      <td>74</td>\n",
       "      <td>Buy Teenage Mutant Ninja Turtles 4: Turtles in...</td>\n",
       "      <td>Teenage Mutant Ninja Turtles IV: Turtles in Time</td>\n",
       "      <td>B000035Y3N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35109</th>\n",
       "      <td>460</td>\n",
       "      <td>A 10 movie collection of women action flicks. ...</td>\n",
       "      <td>Women Who Kick Butt 10 Movie Pack (2001)</td>\n",
       "      <td>B00005B7BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35110</th>\n",
       "      <td>158</td>\n",
       "      <td>This huarache sandal is designed for all-day c...</td>\n",
       "      <td>Softspots Women's Tela Leather Sandal</td>\n",
       "      <td>B0002KIFAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35111</th>\n",
       "      <td>340</td>\n",
       "      <td>The Wrangler Cowboy Cut jean is a Western Wear...</td>\n",
       "      <td>Amazon.com: Wrangler Men's Big &amp;amp; Tall Cowb...</td>\n",
       "      <td>B000FA2832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35112 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_ind                                            content  \\\n",
       "0             247  Premium quality five pocket jean from Wrangler...   \n",
       "1             453  If you're looking for a different kind of anim...   \n",
       "2             228  First things first: Yes, Thinking XXX features...   \n",
       "3             223  Feathertouch. 100% Polyester Machine Wash Warm...   \n",
       "4             312  When you need outstanding fuel delivery, easy ...   \n",
       "...           ...                                                ...   \n",
       "35107         473  SArah Walker, Anthony Rolfe Johnson, Jean Rigb...   \n",
       "35108          74  Buy Teenage Mutant Ninja Turtles 4: Turtles in...   \n",
       "35109         460  A 10 movie collection of women action flicks. ...   \n",
       "35110         158  This huarache sandal is designed for all-day c...   \n",
       "35111         340  The Wrangler Cowboy Cut jean is a Western Wear...   \n",
       "\n",
       "                                                   title         uid  \n",
       "0      Amazon.com: Wrangler Men's Rugged Wear Relaxed...  B0000CBALT  \n",
       "1      Sakura Diaries - Complete Series Collector's E...  B00005QFDT  \n",
       "2                     Thinking XXX (Extended Cut) (2006)  B000BNXD50  \n",
       "3      Amazon.com: Petite Feathertouch Pull-On Pant: ...  B0002LK9V2  \n",
       "4                                ACDelco EP386 Fuel Pump  B000C9PA54  \n",
       "...                                                  ...         ...  \n",
       "35107                          Britten - Gloriana (1984)  B000I2IUM0  \n",
       "35108   Teenage Mutant Ninja Turtles IV: Turtles in Time  B000035Y3N  \n",
       "35109           Women Who Kick Butt 10 Movie Pack (2001)  B00005B7BW  \n",
       "35110              Softspots Women's Tela Leather Sandal  B0002KIFAK  \n",
       "35111  Amazon.com: Wrangler Men's Big &amp; Tall Cowb...  B000FA2832  \n",
       "\n",
       "[35112 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PS3train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89063bd",
   "metadata": {},
   "source": [
    "# Torchtext for classifying text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c7d3fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9c3ae5",
   "metadata": {},
   "source": [
    " Basic data processing building blocks for raw text string.\n",
    "* `tokenizer` - for separating the english basics into tokens\n",
    "* `vocabulary` - The vocabulary block converts a list of tokens into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5b675ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3ec6cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c117b323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "296575b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object yield_tokens at 0x0000021271E34200>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_tokens(iter(PS3train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f4988f5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'map' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vocab \u001b[38;5;241m=\u001b[39m build_vocab_from_iterator(yield_tokens(\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mPS3train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m()), specials\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<unk>\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      2\u001b[0m vocab\u001b[38;5;241m.\u001b[39mset_default_index(vocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<unk>\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'map' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab_from_iterator(yield_tokens(iter(PS3train).items()), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4bf56206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6fc9bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x : int(float(x)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "243f5b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[465, 9, 3, 28, 1667]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('here is the an example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0d8e48bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[683,\n",
       " 243,\n",
       " 684,\n",
       " 735,\n",
       " 1351,\n",
       " 26,\n",
       " 1909,\n",
       " 1347,\n",
       " 215,\n",
       " 2,\n",
       " 16,\n",
       " 1471,\n",
       " 202,\n",
       " 1351,\n",
       " 9,\n",
       " 125,\n",
       " 26,\n",
       " 526,\n",
       " 232,\n",
       " 2073,\n",
       " 10,\n",
       " 424,\n",
       " 13,\n",
       " 521,\n",
       " 1335,\n",
       " 8,\n",
       " 3,\n",
       " 1789,\n",
       " 4,\n",
       " 3116,\n",
       " 10,\n",
       " 219,\n",
       " 2,\n",
       " 523,\n",
       " 14,\n",
       " 17,\n",
       " 1909,\n",
       " 1698,\n",
       " 4464,\n",
       " 1471,\n",
       " 202,\n",
       " 2572,\n",
       " 197,\n",
       " 117,\n",
       " 18,\n",
       " 5,\n",
       " 275,\n",
       " 8638,\n",
       " 1,\n",
       " 25,\n",
       " 3297,\n",
       " 209,\n",
       " 10,\n",
       " 28,\n",
       " 6221,\n",
       " 307,\n",
       " 6,\n",
       " 2460,\n",
       " 1544,\n",
       " 2471,\n",
       " 26,\n",
       " 3,\n",
       " 219,\n",
       " 6,\n",
       " 32,\n",
       " 304,\n",
       " 487,\n",
       " 2,\n",
       " 70,\n",
       " 1909,\n",
       " 1698,\n",
       " 4464,\n",
       " 1471,\n",
       " 202,\n",
       " 2572,\n",
       " 15,\n",
       " 87,\n",
       " 10,\n",
       " 1440,\n",
       " 23,\n",
       " 15,\n",
       " 62,\n",
       " 1810,\n",
       " 14,\n",
       " 3269,\n",
       " 117,\n",
       " 526,\n",
       " 232,\n",
       " 2073,\n",
       " 321,\n",
       " 1471,\n",
       " 184,\n",
       " 735,\n",
       " 233,\n",
       " 185,\n",
       " 3147,\n",
       " 1,\n",
       " 521,\n",
       " 979,\n",
       " 519,\n",
       " 826,\n",
       " 738,\n",
       " 392,\n",
       " 9252,\n",
       " 5373,\n",
       " 2122,\n",
       " 210,\n",
       " 1107,\n",
       " 2415,\n",
       " 202,\n",
       " 315,\n",
       " 105,\n",
       " 1444,\n",
       " 261,\n",
       " 969,\n",
       " 860,\n",
       " 722,\n",
       " 2,\n",
       " 328,\n",
       " 2,\n",
       " 857,\n",
       " 89,\n",
       " 4,\n",
       " 76,\n",
       " 62,\n",
       " 258,\n",
       " 2963,\n",
       " 557,\n",
       " 62,\n",
       " 523,\n",
       " 14,\n",
       " 17,\n",
       " 1909,\n",
       " 2944,\n",
       " 1487,\n",
       " 1698,\n",
       " 4464,\n",
       " 1471,\n",
       " 202,\n",
       " 2572]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline(PS3train.iloc[0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a9649e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "40b5be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = PS3train.iloc[1:, :2]\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch.items():\n",
    "        label_list = torch.tensor(label_pipeline(_label), dtype = torch.int64)\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "        label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "dataloader = DataLoader((iter(PS3train.iloc[:].items())), batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "09e92ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_ind</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>453</td>\n",
       "      <td>If you're looking for a different kind of anim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228</td>\n",
       "      <td>First things first: Yes, Thinking XXX features...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>223</td>\n",
       "      <td>Feathertouch. 100% Polyester Machine Wash Warm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312</td>\n",
       "      <td>When you need outstanding fuel delivery, easy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>85</td>\n",
       "      <td>Cart only.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35107</th>\n",
       "      <td>473</td>\n",
       "      <td>SArah Walker, Anthony Rolfe Johnson, Jean Rigb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35108</th>\n",
       "      <td>74</td>\n",
       "      <td>Buy Teenage Mutant Ninja Turtles 4: Turtles in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35109</th>\n",
       "      <td>460</td>\n",
       "      <td>A 10 movie collection of women action flicks. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35110</th>\n",
       "      <td>158</td>\n",
       "      <td>This huarache sandal is designed for all-day c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35111</th>\n",
       "      <td>340</td>\n",
       "      <td>The Wrangler Cowboy Cut jean is a Western Wear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35111 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_ind                                            content\n",
       "1             453  If you're looking for a different kind of anim...\n",
       "2             228  First things first: Yes, Thinking XXX features...\n",
       "3             223  Feathertouch. 100% Polyester Machine Wash Warm...\n",
       "4             312  When you need outstanding fuel delivery, easy ...\n",
       "5              85                                         Cart only.\n",
       "...           ...                                                ...\n",
       "35107         473  SArah Walker, Anthony Rolfe Johnson, Jean Rigb...\n",
       "35108          74  Buy Teenage Mutant Ninja Turtles 4: Turtles in...\n",
       "35109         460  A 10 movie collection of women action flicks. ...\n",
       "35110         158  This huarache sandal is designed for all-day c...\n",
       "35111         340  The Wrangler Cowboy Cut jean is a Western Wear...\n",
       "\n",
       "[35111 rows x 2 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33930b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b651f2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4838c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8811f22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class = len(set([label for (label, text) in iter(PS3train.iloc[:, 0:2].items())]))\n",
    "num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "41a85343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99076"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4eb0d11a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'B0000CBALT'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m num_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPS3train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m)))\n\u001b[0;32m      2\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(vocab)\n\u001b[0;32m      3\u001b[0m emsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n",
      "File \u001b[1;32mC:\\Data\\AI\\AIhackathon\\env\\lib\\site-packages\\pandas\\core\\series.py:893\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m    847\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;124;03m    Return the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;124;03m          dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 893\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'B0000CBALT'"
     ]
    }
   ],
   "source": [
    "num_class = int(torch.max(torch.tensor(np.array(PS3train.iloc[:, 3], dtype = np.float32))))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e35f5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4e5ee8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7e14703d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m     22\u001b[0m                              shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_batch)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 25\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     accu_val \u001b[38;5;241m=\u001b[39m evaluate(valid_dataloader)\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m total_accu \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m total_accu \u001b[38;5;241m>\u001b[39m accu_val:\n",
      "Cell \u001b[1;32mIn[86], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader)\u001b[0m\n\u001b[0;32m      3\u001b[0m total_acc, total_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m log_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (label, text, offsets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      8\u001b[0m     predicted_label \u001b[38;5;241m=\u001b[39m model(text, offsets)\n",
      "File \u001b[1;32mC:\\Data\\AI\\AIhackathon\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mC:\\Data\\AI\\AIhackathon\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mC:\\Data\\AI\\AIhackathon\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[80], line 5\u001b[0m, in \u001b[0;36mcollate_batch\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollate_batch\u001b[39m(batch):\n\u001b[0;32m      4\u001b[0m     label_list, text_list, offsets \u001b[38;5;241m=\u001b[39m [], [], [\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (_label, _text) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[0;32m      6\u001b[0m         label_list \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(label_pipeline(_label), dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[0;32m      7\u001b[0m         processed_text \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(text_pipeline(_text), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_dataset = to_map_style_dataset(PS3train.items())\n",
    "test_dataset = to_map_style_dataset(PS3test.items())\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
